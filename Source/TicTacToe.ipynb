{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bfabb98-690e-4dba-9b94-3664ab34f2cd",
   "metadata": {},
   "source": [
    "# TicTacToe Common"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b6dcb0-c16e-4b53-8d1e-18b1d1533469",
   "metadata": {},
   "source": [
    "## Game Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe3ab5b-eadb-4e5b-b0c4-80f592dbe283",
   "metadata": {},
   "source": [
    "### TicTacToe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26f9acc-061c-4f1f-a805-d6d592938df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from enum import Enum\n",
    "import re\n",
    "\n",
    "class Role(Enum):\n",
    "    NoRole = 0\n",
    "    Player1 = 1\n",
    "    Player2 = -1\n",
    "    \n",
    "class TicTacToe:\n",
    "    def __init__(self, role1_enum, role2_enum, roleNone_enum):\n",
    "        if role1_enum == role2_enum or role1_enum == roleNone_enum or role2_enum == roleNone_enum:\n",
    "            raise Exception(f'[startGame] duplicated roles:{role1_enum},{role2_enum},{roleNone_enum}')\n",
    "        \n",
    "        self.size = 3\n",
    "        self.lineLenToWin = self.size\n",
    "        self.isInit = False\n",
    "        self.totalSteps = self.size * self.size\n",
    "        self.role1 = role1_enum\n",
    "        self.role2 = role2_enum\n",
    "        self.roleNone = roleNone_enum\n",
    "        \n",
    "    def startGame(self, role):\n",
    "        if role != self.role1 and role != self.role2:\n",
    "            raise Exception(f'[startGame] wrong role={role}')\n",
    "        \n",
    "        self.isInit = True\n",
    "        self.roleTurn = role\n",
    "        self.board = np.full(self.size * self.size, self.roleNone.value)\n",
    "        self.winner = self.roleNone\n",
    "        self.isEnded = False\n",
    "        self.curStep = 0\n",
    "        \n",
    "    def makeStep(self, pos):\n",
    "        if not self.isInit:\n",
    "            raise Exception(f'[makeStep] game not started')\n",
    "        if self.board[pos] != self.roleNone.value:\n",
    "            raise Exception(f'[makeStep] position={pos} has already been taken by {self.board[pos]}') \n",
    "        if self.isEnded:\n",
    "            print('[makeStep] game is ended')\n",
    "            return\n",
    "\n",
    "        self.curStep += 1\n",
    "        self.board[pos] = self.roleTurn.value\n",
    "        self.roleTurn = self.role2 if self.roleTurn == self.role1 else self.role1\n",
    "        if self.checkWinner() or self.curStep == self.totalSteps:\n",
    "            self.isEnded = True\n",
    "\n",
    "    def checkSingleLineWinner(self, startPos, lineDotOffset):\n",
    "        pos = startPos\n",
    "        for i in range(1, self.lineLenToWin):\n",
    "            pos += lineDotOffset\n",
    "            if self.board[startPos] != self.board[pos]:\n",
    "                return self.roleNone.value\n",
    "        return self.board[startPos]\n",
    "\n",
    "    def checkMultiLineWinner(self, startHeadPos, lineCount, lineHeadOffset, lineDotOffset):\n",
    "        pos = startHeadPos\n",
    "        for i in range(0, lineCount): \n",
    "            winner = self.checkSingleLineWinner(pos, lineDotOffset)\n",
    "            pos += lineHeadOffset\n",
    "            if winner != self.roleNone.value:\n",
    "                self.winner = self.role1 if winner == self.role1.value else self.role2\n",
    "                return True\n",
    "        return False\n",
    "            \n",
    "    def checkWinner(self):\n",
    "        return (\n",
    "            # check rows line\n",
    "            self.checkMultiLineWinner(\n",
    "                startHeadPos=0, \n",
    "                lineCount=self.size, \n",
    "                lineHeadOffset=self.size, \n",
    "                lineDotOffset=1\n",
    "            ) or\n",
    "            # check columns line\n",
    "            self.checkMultiLineWinner(\n",
    "                startHeadPos=0, \n",
    "                lineCount=self.size, \n",
    "                lineHeadOffset=1, \n",
    "                lineDotOffset=self.size\n",
    "            ) or\n",
    "            # check '\\' line\n",
    "            self.checkMultiLineWinner(\n",
    "                startHeadPos=0, \n",
    "                lineCount=1, \n",
    "                lineHeadOffset=0, \n",
    "                lineDotOffset=self.size + 1\n",
    "            ) or\n",
    "            # check '/' line\n",
    "            self.checkMultiLineWinner(\n",
    "                startHeadPos=self.size - 1, \n",
    "                lineCount=1, \n",
    "                lineHeadOffset=0, \n",
    "                lineDotOffset=self.size - 1\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def getEmptyPos(self):\n",
    "        return np.where(self.board == 0)[0]\n",
    "\n",
    "    def print(self):\n",
    "        boardStr = ''\n",
    "        for i in range(0, self.size):\n",
    "            boardStr += '|'\n",
    "            for j in range(0, self.size):\n",
    "                role = self.board[i*self.size + j]\n",
    "                symbol = ' '\n",
    "                if role == self.role1.value:\n",
    "                    symbol = 'O'\n",
    "                elif role == self.role2.value:\n",
    "                    symbol = 'X'\n",
    "                boardStr += symbol + '|'\n",
    "            boardStr += '\\n'\n",
    "        print('Game Board:')\n",
    "        print(boardStr[:-1])\n",
    "        print('Game Ended:', self.isEnded)\n",
    "        print('Winner:', self.winner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f2e570-b1a0-414e-8936-600416aa8035",
   "metadata": {},
   "source": [
    "### Test Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14e0ae3-919d-47cc-ab26-93aa4b9d9c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[makeStep] game is ended\n",
      "Game Board:\n",
      "|X|O|O|\n",
      "|O|X|X|\n",
      "|O| |X|\n",
      "Game Ended: True\n",
      "Winner: Role.Player2\n"
     ]
    }
   ],
   "source": [
    "b = TicTacToe(Role.Player1, Role.Player2, Role.NoRole)\n",
    "b.startGame(Role.Player1)\n",
    "b.makeStep(1)\n",
    "b.makeStep(0)\n",
    "b.makeStep(2)\n",
    "b.makeStep(4)\n",
    "b.makeStep(3)\n",
    "b.makeStep(5)\n",
    "b.makeStep(6)\n",
    "b.makeStep(8)\n",
    "b.makeStep(7)\n",
    "b.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa0a44a-ccda-4dd2-aa22-d1b0435096ab",
   "metadata": {},
   "source": [
    "## Common Agent Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cfa5ae-94f6-4da0-bbab-1c0da56971f0",
   "metadata": {},
   "source": [
    "### Agent Base Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc993c2e-5943-4a7b-92dd-a1a510271c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentBase:\n",
    "    def __init__(self, role):\n",
    "        self.role = role\n",
    "\n",
    "    def onEpisodeReset(self):\n",
    "        pass\n",
    "        \n",
    "    def chosseAction(self, gameHandler):\n",
    "        raise Exception('[chosseAction] not implemented')\n",
    "\n",
    "    def updateValue(self, reward):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d0db8a-c9f0-402b-a175-8a1780be67ee",
   "metadata": {},
   "source": [
    "### Random Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac16e36c-4ea7-484a-b420-8faf3afe87e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandAgent(AgentBase):\n",
    "    def chosseAction(self, gameHandler):\n",
    "        positions = gameHandler.getEmptyPos()\n",
    "        idx = np.random.choice(len(positions))\n",
    "        actionPos = positions[idx]\n",
    "        return actionPos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88a0f88-9dc5-4016-af6b-72b836767cbf",
   "metadata": {},
   "source": [
    "### Human Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981903da-e419-4c64-93ba-c719a95cdf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanAgent(AgentBase):\n",
    "    def chosseAction(self, gameHandler):\n",
    "        positions = gameHandler.getEmptyPos()\n",
    "        while True:\n",
    "            gameHandler.print()\n",
    "            row = int(input(\"Input your action row:\"))\n",
    "            col = int(input(\"Input your action col:\"))\n",
    "            actionPos = row * gameHandler.size + col\n",
    "            if actionPos in positions:\n",
    "                return actionPos\n",
    "            else:\n",
    "                print(f'Position ({row},{col}) has already been taken! Try again.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4ed5ff-98c3-466a-8a1d-f9aa748be3dd",
   "metadata": {},
   "source": [
    "# Q-Learning Episode-Based (Monte Carlo)\n",
    "更大范围的自举（Bootstrapping）：从根到叶子节点一整条线的自举"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e1e0d2-97f0-419e-89a5-77e01fc84c17",
   "metadata": {},
   "source": [
    "## Agent Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e807a59-9024-4ee2-ad54-52f19c1aeb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIAgent_QE(AgentBase):\n",
    "    def __init__(self, role, lr=0.2, decayGamma=0.9, exploRate=0.3):\n",
    "        super().__init__(role)\n",
    "        self.learningRate = lr\n",
    "        self.decayGamma = decayGamma\n",
    "        self.exploRate = exploRate\n",
    "        self.Q = {}\n",
    "        self.decisions = []\n",
    "        self.isTraining = True\n",
    "\n",
    "    def getStateActionkey(self, boardState, actionPos):\n",
    "        return str(boardState) + str(actionPos)\n",
    "        \n",
    "    def getStateActionValue(self, stateActionkey):\n",
    "        value = self.Q.get(stateActionkey)\n",
    "        if value is None:\n",
    "            return 0;\n",
    "        return value\n",
    "\n",
    "    def setStateActionValue(self, stateActionkey, value):\n",
    "        self.Q[stateActionkey] = value\n",
    "        \n",
    "    def chosseAction(self, gameHandler):\n",
    "        positions = gameHandler.getEmptyPos()\n",
    "        boardState = gameHandler.board\n",
    "        \n",
    "        if self.isTraining and np.random.uniform(0, 1) < self.exploRate:\n",
    "            # take random action\n",
    "            idx = np.random.choice(len(positions))\n",
    "            actionPos = positions[idx]\n",
    "        else:\n",
    "            maxVal = -9999\n",
    "            for pos in positions:\n",
    "                stateActionkey = self.getStateActionkey(boardState, pos)\n",
    "                value = self.getStateActionValue(stateActionkey)\n",
    "                if value > maxVal:\n",
    "                    maxVal = value\n",
    "                    actionPos = pos\n",
    "\n",
    "        stateActionkey = self.getStateActionkey(boardState, actionPos)\n",
    "        self.decisions.append(stateActionkey)\n",
    "        return actionPos\n",
    "\n",
    "    def updateValue(self, reward):\n",
    "        if not self.isTraining:\n",
    "            return\n",
    "        # only the final step has reward\n",
    "        G_tNext = reward \n",
    "        reward = 0\n",
    "        for stateActionkey in reversed(self.decisions):\n",
    "            # G_t is the total accumulated reward from time step t\n",
    "            G_t = reward + self.decayGamma * G_tNext # bellman equation\n",
    "            Q_t = self.getStateActionValue(stateActionkey)\n",
    "            Q_t += self.learningRate * (G_t - Q_t) # update Q with （weighted Monte Carlo method）\n",
    "            self.setStateActionValue(stateActionkey, Q_t)\n",
    "            G_tNext = Q_t # use Q_t or G_t(mean value or cur value)\n",
    "        self.decisions = []    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa8779c-e375-4d6d-a917-ac1f91414bdc",
   "metadata": {},
   "source": [
    "## Eviroment Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c672b78-7830-46d4-88ab-e15f4063e3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Enviroment:\n",
    "    def __init__(self, game, agents):\n",
    "        self.game = game\n",
    "        self.agents = {}\n",
    "        self.winRates = {}\n",
    "        self.roles = []\n",
    "        for agent in agents:\n",
    "            self.winRates[agent.role] = 0\n",
    "            self.agents[agent.role] = agent\n",
    "            self.roles.append(agent.role)\n",
    "\n",
    "    def getWinRateByRole(self, role):\n",
    "        return self.winRates.get(role)\n",
    "     \n",
    "    def getAgentByRole(self, role):\n",
    "        return self.agents.get(role)\n",
    "\n",
    "    def playGame(self, episodes, onEpisodeEnd = None):\n",
    "        winCount = {}\n",
    "        for role in self.roles:\n",
    "            self.winRates[role] = 0\n",
    "            winCount[role] = 0\n",
    "\n",
    "        episode = 0\n",
    "        for episode in range(1, episodes+1):\n",
    "            # restart the game\n",
    "            startRole = self.roles[np.random.choice(len(self.roles))]# random role\n",
    "            self.game.startGame(startRole);\n",
    "            # play an episode\n",
    "            while not self.game.isEnded:\n",
    "                agent = self.agents[self.game.roleTurn]\n",
    "                if agent is None:\n",
    "                    raise Exception(f'[TrainingEnviroment] env has no agent with role={self.game.roleTurn}') \n",
    "                actionPos = agent.chosseAction(self.game)\n",
    "                self.game.makeStep(actionPos)\n",
    "            # update values\n",
    "            for role in self.roles:\n",
    "                # current agent is the winner\n",
    "                if role is self.game.winner:\n",
    "                    reward = 1\n",
    "                    winCount[role] += 1\n",
    "                    self.winRates[role] = winCount[role] / episode\n",
    "                # draw\n",
    "                elif self.game.winner is Role.NoRole:\n",
    "                    reward = 0\n",
    "                # current agent is the losser\n",
    "                else:\n",
    "                    reward = -1\n",
    "                self.agents[role].updateValue(reward)\n",
    "                \n",
    "            if onEpisodeEnd != None:\n",
    "                onEpisodeEnd(self, episode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2014704d-a0c4-425f-a20f-8ae170caecb4",
   "metadata": {},
   "source": [
    "## Play the game"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5237afd4-690c-4902-8684-c6acf6fce1bd",
   "metadata": {},
   "source": [
    "### Training with RandAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb80f588-4a70-4be6-8edd-7a1ebc787096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[episode = 5000] AI1 win rate is 0.563\n",
      "[episode = 5000] RandAgent win rate is 0.3163265306122449\n",
      "[episode = 10000] AI1 win rate is 0.6098\n",
      "[episode = 10000] RandAgent win rate is 0.26974276849164247\n",
      "[episode = 15000] AI1 win rate is 0.6381517535671423\n",
      "[episode = 15000] RandAgent win rate is 0.2424\n",
      "[episode = 20000] AI1 win rate is 0.6559155915591559\n",
      "[episode = 20000] RandAgent win rate is 0.228\n",
      "[episode = 25000] AI1 win rate is 0.6694267770710829\n",
      "[episode = 25000] RandAgent win rate is 0.21462575509061088\n",
      "[episode = 30000] AI1 win rate is 0.6775\n",
      "[episode = 30000] RandAgent win rate is 0.20646193858157447\n",
      "[episode = 35000] AI1 win rate is 0.6856106063203612\n",
      "[episode = 35000] RandAgent win rate is 0.19980570873453526\n",
      "[episode = 40000] AI1 win rate is 0.692\n",
      "[episode = 40000] RandAgent win rate is 0.19452986324658117\n",
      "[episode = 45000] AI1 win rate is 0.6980377341718705\n",
      "[episode = 45000] RandAgent win rate is 0.1895777777777778\n",
      "[episode = 50000] AI1 win rate is 0.70348\n",
      "[episode = 50000] RandAgent win rate is 0.18567713542708542\n",
      "[episode = 55000] AI1 win rate is 0.7069711625877305\n",
      "[episode = 55000] RandAgent win rate is 0.1826909090909091\n",
      "[episode = 60000] AI1 win rate is 0.71005\n",
      "[episode = 60000] RandAgent win rate is 0.18009533968931263\n"
     ]
    }
   ],
   "source": [
    "def onEpisodeEnd(env, episode):\n",
    "    if episode % 5000 != 0:\n",
    "        return\n",
    "    print(f'[episode = {episode}] AI1 win rate is {env.getWinRateByRole(Role.Player1)}')\n",
    "    print(f'[episode = {episode}] RandAgent win rate is {env.getWinRateByRole(Role.Player2)}')\n",
    "\n",
    "game = TicTacToe(Role.Player1, Role.Player2, Role.NoRole)\n",
    "agent1 = AIAgent_QE(Role.Player1, lr=0.12, decayGamma=0.9, exploRate=0.4)\n",
    "agent2 = RandAgent(Role.Player2)\n",
    "trainingEnv = Enviroment(game, [agent1, agent2])\n",
    "trainingEnv.playGame(60000, onEpisodeEnd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ed47fc-45cc-4601-90d7-e653327c74ed",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Training with another AI Agent\n",
    "Best Parameters:\n",
    "AIAgent_QE lr=0.12, decayGamma=0.9, exploRate=0.4 (best win rate against RandAgent is 0.9462)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c131c1-6330-4a7e-92f9-564389b48f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[episode = 5000] AI1 win rate is 0.38015206082432973\n",
      "[episode = 5000] AI2 win rate is 0.4097277822257806\n",
      "[episode = 10000] AI1 win rate is 0.3703\n",
      "[episode = 10000] AI2 win rate is 0.39965986394557823\n",
      "[episode = 15000] AI1 win rate is 0.3760250683378892\n",
      "[episode = 15000] AI2 win rate is 0.38826666666666665\n",
      "[episode = 20000] AI1 win rate is 0.3697\n",
      "[episode = 20000] AI2 win rate is 0.3866693334666733\n",
      "[episode = 25000] AI1 win rate is 0.36817472698907955\n",
      "[episode = 25000] AI2 win rate is 0.383085970316438\n",
      "[episode = 30000] AI1 win rate is 0.36504867315642087\n",
      "[episode = 30000] AI2 win rate is 0.3819\n",
      "[episode = 35000] AI1 win rate is 0.3612960370296294\n",
      "[episode = 35000] AI2 win rate is 0.3814653940675544\n",
      "[episode = 40000] AI1 win rate is 0.3607590189754744\n",
      "[episode = 40000] AI2 win rate is 0.3776\n",
      "[episode = 45000] AI1 win rate is 0.36004444444444444\n",
      "[episode = 45000] AI2 win rate is 0.37533613352001244\n",
      "[episode = 50000] AI1 win rate is 0.35886\n",
      "[episode = 50000] AI2 win rate is 0.37274981998559886\n",
      "[episode = 55000] AI1 win rate is 0.35745454545454547\n",
      "[episode = 55000] AI2 win rate is 0.37184988545038\n",
      "[episode = 60000] AI1 win rate is 0.35675\n",
      "[episode = 60000] AI2 win rate is 0.3698561642694045\n"
     ]
    }
   ],
   "source": [
    "def onEpisodeEnd(env, episode):\n",
    "    if episode % 5000 == 0:\n",
    "        print(f'[episode = {episode}] AI1 win rate is {env.getWinRateByRole(Role.Player1)}')\n",
    "        print(f'[episode = {episode}] AI2 win rate is {env.getWinRateByRole(Role.Player2)}')\n",
    "\n",
    "game = TicTacToe(Role.Player1, Role.Player2, Role.NoRole)\n",
    "agent1 = AIAgent_QE(Role.Player1, lr=0.1, decayGamma=0.9, exploRate=0.4)\n",
    "agent2 = AIAgent_QE(Role.Player2, lr=0.1, decayGamma=0.9, exploRate=0.4)\n",
    "trainingEnv = Enviroment(game, [agent1, agent2])\n",
    "trainingEnv.playGame(60000, onEpisodeEnd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db551fa2-4996-4b4a-b2ab-42f52fc8b53b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Inference with RandAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64aa4e05-8714-437d-8950-2dece2f83e50",
   "metadata": {},
   "source": [
    "when win rate is 0.9462, is hard for human to win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e134065c-2839-4f8c-b730-648825ec0232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[episode = 5000] AI1 win rate is 0.9119823964792959\n",
      "[episode = 5000] RandAgent win rate is 0.016908212560386472\n"
     ]
    }
   ],
   "source": [
    "def onEpisodeEnd3(env, episode):\n",
    "    if episode % 5000 != 0:\n",
    "        return\n",
    "    print(f'[episode = {episode}] AI1 win rate is {env.getWinRateByRole(Role.Player1)}')\n",
    "    print(f'[episode = {episode}] RandAgent win rate is {env.getWinRateByRole(Role.Player2)}')\n",
    "\n",
    "agent1.isTraining = False\n",
    "agent2 = RandAgent(Role.Player2)\n",
    "infEnv = Enviroment(game, [agent1, agent2])\n",
    "infEnv.playGame(5000, onEpisodeEnd3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037c9522-de1f-47ec-b620-3d17a566a2d7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Inference with Human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d98843-6494-4c5a-af9c-aeec125c9279",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onEpisodeEnd2(env, episode):\n",
    "    env.game.print()\n",
    "    print(f'[episode = {episode}] AI1 win rate is {env.getWinRateByRole(Role.Player1)}')\n",
    "    print(f'[episode = {episode}] Your win rate is {env.getWinRateByRole(Role.Player2)}')\n",
    "\n",
    "agent1.isTraining = False\n",
    "agent2 = HumanAgent(Role.Player2)\n",
    "infEnv = Enviroment(game, [agent1, agent2])\n",
    "infEnv.playGame(5, onEpisodeEnd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a00a3ee-70d5-4181-bbe8-b6c32e14d85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,5,3]\n",
    "b = np.ones(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d720bdb-fc52-45e3-a608-6ef6dfd308a1",
   "metadata": {},
   "source": [
    "# Q-Learning Step-Based (Temporal Difference)\n",
    "自举法Bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c7c09e-82c2-4971-ba58-fa2255dfaada",
   "metadata": {},
   "source": [
    "## Agent Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d989e1-3a0b-4587-85dc-405e63083fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIAgent_QS(AgentBase):\n",
    "    def __init__(self, role, lr=0.2, decayGamma=0.9, exploRate=0.3):\n",
    "        super().__init__(role)\n",
    "        self.learningRate = lr\n",
    "        self.decayGamma = decayGamma\n",
    "        self.exploRate = exploRate\n",
    "        self.Q = {}\n",
    "        self.isTraining = True\n",
    "\n",
    "    def onEpisodeReset(self):\n",
    "        self.stateActionkey_t = None\n",
    "        self.stateActionkey_tNext = None\n",
    "\n",
    "    def getStateActionkey(self, boardState, actionPos):\n",
    "        return str(boardState) + str(actionPos)\n",
    "        \n",
    "    def getStateActionValue(self, stateActionkey):\n",
    "        value = self.Q.get(stateActionkey)\n",
    "        if value is None:\n",
    "            return 0;\n",
    "        return value\n",
    "\n",
    "    def setStateActionValue(self, stateActionkey, value):\n",
    "        self.Q[stateActionkey] = value\n",
    "        \n",
    "    def chosseAction(self, gameHandler):\n",
    "        positions = gameHandler.getEmptyPos()\n",
    "        boardState = gameHandler.board\n",
    "\n",
    "        actionPos = None\n",
    "        if self.isTraining and np.random.uniform(0, 1) < self.exploRate:\n",
    "            # take random action\n",
    "            idx = np.random.choice(len(positions))\n",
    "            actionPos = positions[idx]\n",
    "        else:\n",
    "            maxVal = -9999\n",
    "            for pos in positions:\n",
    "                stateActionkey = self.getStateActionkey(boardState, pos)\n",
    "                value = self.getStateActionValue(stateActionkey)\n",
    "                if value > maxVal:\n",
    "                    maxVal = value\n",
    "                    actionPos = pos\n",
    "\n",
    "        self.stateActionkey_tNext = self.getStateActionkey(boardState, actionPos)\n",
    "        return actionPos\n",
    "\n",
    "    def updateValue(self, reward):\n",
    "        if not self.isTraining:\n",
    "            return\n",
    "\n",
    "        if self.stateActionkey_t != None:\n",
    "            Q_t = self.getStateActionValue(self.stateActionkey_t)\n",
    "            Q_tNext = self.getStateActionValue(self.stateActionkey_tNext)\n",
    "            \n",
    "            G_t = reward + self.decayGamma * Q_tNext # bellman equation\n",
    "            Q_t += self.learningRate * (G_t - Q_t) # update Q with Monte Carlo method\n",
    "        \n",
    "            self.setStateActionValue(self.stateActionkey_t, Q_t)\n",
    "            \n",
    "        self.stateActionkey_t = self.stateActionkey_tNext\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee3f8bb-e8d2-4085-a616-74362eaf1ac6",
   "metadata": {},
   "source": [
    "## Eviroment Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9438d9-3d7f-488b-b979-f4ef2e0160d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Enviroment:\n",
    "    def __init__(self, game, agents):\n",
    "        self.game = game\n",
    "        self.agents = {}\n",
    "        self.winRates = {}\n",
    "        self.roles = []\n",
    "        for agent in agents:\n",
    "            self.winRates[agent.role] = 0\n",
    "            self.agents[agent.role] = agent\n",
    "            self.roles.append(agent.role)\n",
    "\n",
    "    def getWinRateByRole(self, role):\n",
    "        return self.winRates.get(role)\n",
    "     \n",
    "    def getAgentByRole(self, role):\n",
    "        return self.agents.get(role)\n",
    "\n",
    "    def playGame(self, episodes, onEpisodeEnd = None):\n",
    "        winCount = {}\n",
    "        for role in self.roles:\n",
    "            self.winRates[role] = 0\n",
    "            winCount[role] = 0\n",
    "\n",
    "        episode = 0\n",
    "        for episode in range(1, episodes+1):\n",
    "            \n",
    "            # restart the game\n",
    "            startRole = self.roles[np.random.choice(len(self.roles))]# random role\n",
    "            self.game.startGame(startRole);\n",
    "            for role in self.roles:\n",
    "                self.agents[role].onEpisodeReset()\n",
    "                \n",
    "            # play an episode\n",
    "            while not self.game.isEnded:\n",
    "                agent = self.agents[self.game.roleTurn]\n",
    "                if agent is None:\n",
    "                    raise Exception(f'[TrainingEnviroment] env has no agent with role={self.game.roleTurn}') \n",
    "                actionPos = agent.chosseAction(self.game)\n",
    "                self.game.makeStep(actionPos)\n",
    "                agent.updateValue(reward=0)\n",
    "\n",
    "            # update value\n",
    "            for role in self.roles:\n",
    "                reward = 0\n",
    "                # current agent is the winner\n",
    "                if role == self.game.winner:\n",
    "                    reward = 1\n",
    "                    winCount[role] += 1\n",
    "                    self.winRates[role] = winCount[role] / episode\n",
    "                # current agent is the losser\n",
    "                else:\n",
    "                    reward = -1\n",
    "                self.agents[role].updateValue(reward)\n",
    "                \n",
    "            if onEpisodeEnd != None:\n",
    "                onEpisodeEnd(self, episode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d3a388-2f66-4360-bafd-c705e26ab43f",
   "metadata": {},
   "source": [
    "## Play the game"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f887938c-c268-4451-a38a-d594a2d10d87",
   "metadata": {},
   "source": [
    "### Training with RandAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250912c4-b542-4de1-91ba-6716a96c2301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[episode = 5000] AI1 win rate is 0.535\n",
      "[episode = 5000] RandAgent win rate is 0.36208967173738993\n",
      "[episode = 10000] AI1 win rate is 0.5656\n",
      "[episode = 10000] RandAgent win rate is 0.334000200060018\n",
      "[episode = 15000] AI1 win rate is 0.5875450060008001\n",
      "[episode = 15000] RandAgent win rate is 0.3171333333333333\n",
      "[episode = 20000] AI1 win rate is 0.5990799539976999\n",
      "[episode = 20000] RandAgent win rate is 0.30835\n",
      "[episode = 25000] AI1 win rate is 0.60872\n",
      "[episode = 25000] RandAgent win rate is 0.30061202448097923\n",
      "[episode = 30000] AI1 win rate is 0.6152333333333333\n",
      "[episode = 30000] RandAgent win rate is 0.2962024472376888\n",
      "[episode = 35000] AI1 win rate is 0.6206463041801195\n",
      "[episode = 35000] RandAgent win rate is 0.2923428571428571\n",
      "[episode = 40000] AI1 win rate is 0.6244\n",
      "[episode = 40000] RandAgent win rate is 0.29053631703962995\n",
      "[episode = 45000] AI1 win rate is 0.6289777777777777\n",
      "[episode = 45000] RandAgent win rate is 0.28745749149829963\n",
      "[episode = 50000] AI1 win rate is 0.6328253130125205\n",
      "[episode = 50000] RandAgent win rate is 0.28546\n",
      "[episode = 55000] AI1 win rate is 0.6359867631550238\n",
      "[episode = 55000] RandAgent win rate is 0.2836\n",
      "[episode = 60000] AI1 win rate is 0.6382333333333333\n",
      "[episode = 60000] RandAgent win rate is 0.28184272809093636\n",
      "[episode = 65000] AI1 win rate is 0.6412923076923077\n",
      "[episode = 65000] RandAgent win rate is 0.2803557141977968\n",
      "[episode = 70000] AI1 win rate is 0.6445377791111302\n",
      "[episode = 70000] RandAgent win rate is 0.2782857142857143\n",
      "[episode = 75000] AI1 win rate is 0.64644\n",
      "[episode = 75000] RandAgent win rate is 0.277173985517876\n",
      "[episode = 80000] AI1 win rate is 0.64825\n",
      "[episode = 80000] RandAgent win rate is 0.27615690392259806\n",
      "[episode = 85000] AI1 win rate is 0.6496194072871445\n",
      "[episode = 85000] RandAgent win rate is 0.27536265985858327\n",
      "[episode = 90000] AI1 win rate is 0.6510994810938142\n",
      "[episode = 90000] RandAgent win rate is 0.2747222222222222\n",
      "[episode = 95000] AI1 win rate is 0.6521684210526316\n",
      "[episode = 95000] RandAgent win rate is 0.27420288634617207\n",
      "[episode = 100000] AI1 win rate is 0.6532495974879247\n",
      "[episode = 100000] RandAgent win rate is 0.27362\n",
      "[episode = 105000] AI1 win rate is 0.6546761904761905\n",
      "[episode = 105000] RandAgent win rate is 0.2727393946320742\n",
      "[episode = 110000] AI1 win rate is 0.6555786870789735\n",
      "[episode = 110000] RandAgent win rate is 0.27235454545454546\n",
      "[episode = 115000] AI1 win rate is 0.6565739130434782\n",
      "[episode = 115000] RandAgent win rate is 0.27200236523795857\n",
      "[episode = 120000] AI1 win rate is 0.6574138117817648\n",
      "[episode = 120000] RandAgent win rate is 0.2717878631310522\n"
     ]
    }
   ],
   "source": [
    "def onEpisodeEnd(env, episode):\n",
    "    if episode % 5000 != 0:\n",
    "        return\n",
    "    print(f'[episode = {episode}] AI1 win rate is {env.getWinRateByRole(Role.Player1)}')\n",
    "    print(f'[episode = {episode}] RandAgent win rate is {env.getWinRateByRole(Role.Player2)}')\n",
    "\n",
    "game = TicTacToe(Role.Player1, Role.Player2, Role.NoRole)\n",
    "agent1 = AIAgent_QS(Role.Player1, lr=0.25, decayGamma=0.9, exploRate=0.5)\n",
    "agent2 = RandAgent(Role.Player2)\n",
    "trainingEnv = Enviroment(game, [agent1, agent2])\n",
    "trainingEnv.playGame(120000, onEpisodeEnd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f98486-7caf-43ec-86e5-ddcd95b523cb",
   "metadata": {},
   "source": [
    "### Training with another AI Agent\n",
    "Best Parameters:\n",
    "AIAgent_QS lr=0.12, decayGamma=0.9, exploRate=0.4 (best win rate against RandAgent is 0.9462)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0188574e-be64-408d-8342-85b32f88454e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[episode = 5000] AI1 win rate is 0.4446\n",
      "[episode = 5000] AI2 win rate is 0.4288857771554311\n",
      "[episode = 10000] AI1 win rate is 0.4479\n",
      "[episode = 10000] AI2 win rate is 0.44096457874724837\n",
      "[episode = 15000] AI1 win rate is 0.4482\n",
      "[episode = 15000] AI2 win rate is 0.44642261785690474\n",
      "[episode = 20000] AI1 win rate is 0.4467\n",
      "[episode = 20000] AI2 win rate is 0.45101765264789717\n",
      "[episode = 25000] AI1 win rate is 0.44309317118054165\n",
      "[episode = 25000] AI2 win rate is 0.45632\n",
      "[episode = 30000] AI1 win rate is 0.44553333333333334\n",
      "[episode = 30000] AI2 win rate is 0.4562970864724315\n",
      "[episode = 35000] AI1 win rate is 0.4447269921997771\n",
      "[episode = 35000] AI2 win rate is 0.45977142857142855\n",
      "[episode = 40000] AI1 win rate is 0.446275\n",
      "[episode = 40000] AI2 win rate is 0.46124806240312016\n",
      "[episode = 45000] AI1 win rate is 0.4467408938373669\n",
      "[episode = 45000] AI2 win rate is 0.46328888888888886\n",
      "[episode = 50000] AI1 win rate is 0.4485889717794356\n",
      "[episode = 50000] AI2 win rate is 0.46418785127107626\n",
      "[episode = 55000] AI1 win rate is 0.44913543882616047\n",
      "[episode = 55000] AI2 win rate is 0.4657090909090909\n",
      "[episode = 60000] AI1 win rate is 0.45056666666666667\n",
      "[episode = 60000] AI2 win rate is 0.466389986165975\n",
      "[episode = 65000] AI1 win rate is 0.4507438804867917\n",
      "[episode = 65000] AI2 win rate is 0.4683764365605625\n",
      "[episode = 70000] AI1 win rate is 0.4516972398422767\n",
      "[episode = 70000] AI2 win rate is 0.46874285714285713\n",
      "[episode = 75000] AI1 win rate is 0.45150666666666667\n",
      "[episode = 75000] AI2 win rate is 0.4704117552936157\n",
      "[episode = 80000] AI1 win rate is 0.45169879246981176\n",
      "[episode = 80000] AI2 win rate is 0.4717125\n",
      "[episode = 85000] AI1 win rate is 0.4530694839878585\n",
      "[episode = 85000] AI2 win rate is 0.4717294117647059\n",
      "[episode = 90000] AI1 win rate is 0.4544939388215425\n",
      "[episode = 90000] AI2 win rate is 0.47128888888888887\n",
      "[episode = 95000] AI1 win rate is 0.45526315789473687\n",
      "[episode = 95000] AI2 win rate is 0.4717201595839869\n",
      "[episode = 100000] AI1 win rate is 0.45626\n",
      "[episode = 100000] AI2 win rate is 0.47176415292458773\n",
      "[episode = 105000] AI1 win rate is 0.45660869730852016\n",
      "[episode = 105000] AI2 win rate is 0.47256190476190474\n",
      "[episode = 110000] AI1 win rate is 0.4566818181818182\n",
      "[episode = 110000] AI2 win rate is 0.47355406461935673\n",
      "[episode = 115000] AI1 win rate is 0.45747354324820216\n",
      "[episode = 115000] AI2 win rate is 0.4737217391304348\n",
      "[episode = 120000] AI1 win rate is 0.4578454820456837\n",
      "[episode = 120000] AI2 win rate is 0.47425\n"
     ]
    }
   ],
   "source": [
    "def onEpisodeEnd(env, episode):\n",
    "    if episode % 5000 == 0:\n",
    "        print(f'[episode = {episode}] AI1 win rate is {env.getWinRateByRole(Role.Player1)}')\n",
    "        print(f'[episode = {episode}] AI2 win rate is {env.getWinRateByRole(Role.Player2)}')\n",
    "\n",
    "game = TicTacToe(Role.Player1, Role.Player2, Role.NoRole)\n",
    "agent1 = AIAgent_QS(Role.Player1, lr=0.25, decayGamma=0.9, exploRate=0.5)\n",
    "agent2 = AIAgent_QS(Role.Player2, lr=0.25, decayGamma=0.9, exploRate=0.5)\n",
    "trainingEnv = Enviroment(game, [agent1, agent2])\n",
    "trainingEnv.playGame(120000, onEpisodeEnd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931fa115-3fc1-4e5f-bd3d-3f7a46106500",
   "metadata": {},
   "source": [
    "### Inference with RandAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33be74c2-1231-401a-8825-6260ecf30bf8",
   "metadata": {},
   "source": [
    "when win rate is 0.9462, is hard for human to win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbece55-7773-4c53-8ab2-0948293880b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[episode = 5000] AI1 win rate is 0.8908\n",
      "[episode = 5000] RandAgent win rate is 0.08494363929146538\n"
     ]
    }
   ],
   "source": [
    "def onEpisodeEnd3(env, episode):\n",
    "    if episode % 5000 != 0:\n",
    "        return\n",
    "    print(f'[episode = {episode}] AI1 win rate is {env.getWinRateByRole(Role.Player1)}')\n",
    "    print(f'[episode = {episode}] RandAgent win rate is {env.getWinRateByRole(Role.Player2)}')\n",
    "\n",
    "agent1.isTraining = False\n",
    "agent2 = RandAgent(Role.Player2)\n",
    "infEnv = Enviroment(game, [agent1, agent2])\n",
    "infEnv.playGame(5000, onEpisodeEnd3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8af382-17d7-4163-9f14-d84cf632464d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Inference with Human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d613681-c360-46b8-9d11-3eaf29588a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game Board:\n",
      "| | | |\n",
      "| | | |\n",
      "| | | |\n",
      "Game Ended: False\n",
      "Winner: Role.NoRole\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input your action row: 1\n",
      "Input your action col: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game Board:\n",
      "|O| | |\n",
      "| |X| |\n",
      "| | | |\n",
      "Game Ended: False\n",
      "Winner: Role.NoRole\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input your action row: 2\n",
      "Input your action col: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game Board:\n",
      "|O| | |\n",
      "|O|X| |\n",
      "| | |X|\n",
      "Game Ended: False\n",
      "Winner: Role.NoRole\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input your action row: 2\n",
      "Input your action col: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game Board:\n",
      "|O|O| |\n",
      "|O|X| |\n",
      "|X| |X|\n",
      "Game Ended: False\n",
      "Winner: Role.NoRole\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input your action row: 2\n",
      "Input your action col: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game Board:\n",
      "|O|O| |\n",
      "|O|X| |\n",
      "|X|X|X|\n",
      "Game Ended: True\n",
      "Winner: Role.Player2\n",
      "[episode = 1] AI1 win rate is 0\n",
      "[episode = 1] Your win rate is 1.0\n",
      "Game Board:\n",
      "| | | |\n",
      "| | | |\n",
      "| | | |\n",
      "Game Ended: False\n",
      "Winner: Role.NoRole\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input your action row: 0\n",
      "Input your action col: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game Board:\n",
      "|X| | |\n",
      "| |O| |\n",
      "| | | |\n",
      "Game Ended: False\n",
      "Winner: Role.NoRole\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input your action row: 0\n",
      "Input your action col: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game Board:\n",
      "|X|X|O|\n",
      "| |O| |\n",
      "| | | |\n",
      "Game Ended: False\n",
      "Winner: Role.NoRole\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input your action row: 2\n",
      "Input your action col: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game Board:\n",
      "|X|X|O|\n",
      "| |O| |\n",
      "|O| |X|\n",
      "Game Ended: True\n",
      "Winner: Role.Player1\n",
      "[episode = 2] AI1 win rate is 0.5\n",
      "[episode = 2] Your win rate is 1.0\n",
      "Game Board:\n",
      "|O| | |\n",
      "| | | |\n",
      "| | | |\n",
      "Game Ended: False\n",
      "Winner: Role.NoRole\n"
     ]
    }
   ],
   "source": [
    "def onEpisodeEnd2(env, episode):\n",
    "    env.game.print()\n",
    "    print(f'[episode = {episode}] AI1 win rate is {env.getWinRateByRole(Role.Player1)}')\n",
    "    print(f'[episode = {episode}] Your win rate is {env.getWinRateByRole(Role.Player2)}')\n",
    "\n",
    "agent1.isTraining = False\n",
    "agent2 = HumanAgent(Role.Player2)\n",
    "infEnv = Enviroment(game, [agent1, agent2])\n",
    "infEnv.playGame(5, onEpisodeEnd2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python-3.9.18 (tensorflow-2.6.0, opencv-4.5.5)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
